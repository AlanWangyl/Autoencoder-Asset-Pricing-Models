{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from models.PCA import PCA\n",
    "from models.FF import FF\n",
    "from models.IPCA import IPCA\n",
    "from models.CA import CA0, CA1, CA2, CA3\n",
    "\n",
    "import gc\n",
    "import argparse\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "from utils import *\n",
    "from analysis import *\n",
    "from analysis import *\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import product\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "select_charcs = ['mvel1', 'mom1m', 'idiovol', 'retvol', 'mom6m', 'beta', 'mom12m', 'turn', 'ill', 'baspread', 'betasq', 'mom36m', 'std_turn', 'dolvol', 'zerotrade', 'indmom', 'maxret', 'dy', 'bm', 'chmom', 'nincr', 'std_dolvol', 'sp', 'rd_sale', 'roaq']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_R2(model, type):\n",
    "    portfolio_ret = pd.read_pickle('data/portfolio_ret.pkl')\n",
    "\n",
    "    oos_ret = portfolio_ret.loc[(portfolio_ret['DATE'] >= OOS_start) & (portfolio_ret['DATE'] <= OOS_end)]\n",
    "    print('type: ', type)\n",
    "    \n",
    "    if isinstance(model, str):\n",
    "        output_path = f'results/{type}/{model}_{type}.csv'\n",
    "    else:\n",
    "        output_path = f'results/{type}/{model.name}_{type}.csv'\n",
    "    \n",
    "    print('path : ', output_path)\n",
    "    model_output = pd.read_csv(output_path)\n",
    "    \n",
    "    residual_square = (oos_ret.set_index('DATE') - model_output.set_index('DATE'))**2\n",
    "    residual_square = (1 - (residual_square == np.inf) * 1.0) * residual_square # drop Inf outliers\n",
    "    \n",
    "    total_square = oos_ret.set_index('DATE')**2\n",
    "    total_square = (1 - (total_square == np.inf) * 1.0) * total_square # drop Inf outliers\n",
    "    \n",
    "    return 1 - np.sum(residual_square.values)/np.sum(total_square.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type:  inference\n",
      "path :  results/inference/CA3_1_inference.csv\n",
      "0.4629420468238765\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m在当前单元格或上一个单元格中执行代码时 Kernel 崩溃。请查看单元格中的代码，以确定故障的可能原因。有关详细信息，请单击 <a href='https://aka.ms/vscodeJupyterKernelCrash'>此处</a>。有关更多详细信息，请查看 Jupyter <a href='command:jupyter.viewOutput'>log</a>。"
     ]
    }
   ],
   "source": [
    "for i in range(1):\n",
    "    print(calculate_R2(f'CA3_{i+1}', 'inference'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_inference_and_predict(model):\n",
    "    \"\"\"\n",
    "    Inference and Prediction of non NN models:\n",
    "    Returns: model.name_inference.csv & model.name_inference.csv saved in path 'results'\n",
    "    \"\"\"\n",
    "    mon_list = pd.read_pickle('data/mon_list.pkl')\n",
    "    test_mons = mon_list.loc[mon_list >= model.test_period[0]]\n",
    "    inference_result = []\n",
    "    predict_result = []\n",
    "    T_bar = tqdm(test_mons.groupby(test_mons.apply(lambda x: x//10000)), colour='red', desc=f'{model.name} Inferencing & Predicting')\n",
    "    \n",
    "    for g in T_bar: # rolling train\n",
    "        T_bar.set_postfix({'Year': g[0]})\n",
    "        model.train_model()\n",
    "        \n",
    "        for m in g[1].to_list():\n",
    "            inference_result.append(model.inference(m))\n",
    "            predict_result.append(model.predict(m))\n",
    "        # model refit (change train period and valid period)\n",
    "        model.refit()\n",
    "\n",
    "    inference_result = pd.DataFrame(inference_result, index=test_mons, columns=CHARAS_LIST)\n",
    "    inference_result.to_csv(f'results/inference/{model.name}_inference.csv')\n",
    "    \n",
    "    predict_result = pd.DataFrame(predict_result, index=test_mons, columns=CHARAS_LIST)\n",
    "    predict_result.to_csv(f'results/predict/{model.name}_predict.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc = pd.read_pickle('data/month_ret.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>permno</th>\n",
       "      <th>date</th>\n",
       "      <th>month</th>\n",
       "      <th>ret-rf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10006</td>\n",
       "      <td>19570329</td>\n",
       "      <td>195703</td>\n",
       "      <td>1.6105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10014</td>\n",
       "      <td>19570329</td>\n",
       "      <td>195703</td>\n",
       "      <td>-0.2300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10022</td>\n",
       "      <td>19570329</td>\n",
       "      <td>195703</td>\n",
       "      <td>-0.6146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10030</td>\n",
       "      <td>19570329</td>\n",
       "      <td>195703</td>\n",
       "      <td>7.5607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10057</td>\n",
       "      <td>19570329</td>\n",
       "      <td>195703</td>\n",
       "      <td>-2.0030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3780454</th>\n",
       "      <td>93427</td>\n",
       "      <td>20161230</td>\n",
       "      <td>201612</td>\n",
       "      <td>-5.8711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3780455</th>\n",
       "      <td>93428</td>\n",
       "      <td>20161230</td>\n",
       "      <td>201612</td>\n",
       "      <td>-0.6324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3780456</th>\n",
       "      <td>93429</td>\n",
       "      <td>20161230</td>\n",
       "      <td>201612</td>\n",
       "      <td>7.2124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3780457</th>\n",
       "      <td>93434</td>\n",
       "      <td>20161230</td>\n",
       "      <td>201612</td>\n",
       "      <td>-4.1967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3780458</th>\n",
       "      <td>93436</td>\n",
       "      <td>20161230</td>\n",
       "      <td>201612</td>\n",
       "      <td>12.7947</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3780459 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         permno      date   month   ret-rf\n",
       "0         10006  19570329  195703   1.6105\n",
       "1         10014  19570329  195703  -0.2300\n",
       "2         10022  19570329  195703  -0.6146\n",
       "3         10030  19570329  195703   7.5607\n",
       "4         10057  19570329  195703  -2.0030\n",
       "...         ...       ...     ...      ...\n",
       "3780454   93427  20161230  201612  -5.8711\n",
       "3780455   93428  20161230  201612  -0.6324\n",
       "3780456   93429  20161230  201612   7.2124\n",
       "3780457   93434  20161230  201612  -4.1967\n",
       "3780458   93436  20161230  201612  12.7947\n",
       "\n",
       "[3780459 rows x 4 columns]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_inference_and_predict_CA(model):\n",
    "    \"\"\"\n",
    "    Inference and Prediction of NN models:\n",
    "    Returns: model.name_inference.csv & model.name_inference.csv saved in path 'results'\n",
    "    \"\"\"\n",
    "    mon_list = pd.read_pickle('data/mon_list.pkl')\n",
    "    test_mons = mon_list.loc[mon_list >= model.test_period[0]]\n",
    "    inference_result = pd.DataFrame()\n",
    "    predict_result = pd.DataFrame()\n",
    "    T_bar = tqdm(test_mons.groupby(test_mons.apply(lambda x: x//10000)), colour='red', desc=f'{model.name} Inferencing & Predicting')\n",
    "    \n",
    "    stock_index = pd.Series(dtype=np.int64)\n",
    "    for g in T_bar: # rolling train\n",
    "        T_bar.set_postfix({'Year': g[0]})\n",
    "\n",
    "        model.reset_weight()\n",
    "        model.release_gpu()\n",
    "        # release GPU memory\n",
    "        for _ in range(6): # call function multiple times to clear the cuda cache\n",
    "            torch.cuda.empty_cache()\n",
    "            \n",
    "        train_loss, val_loss = model.train_model()\n",
    "        # plot loss\n",
    "        plt.plot(train_loss, label='train_loss')\n",
    "        plt.plot(val_loss, label='val_loss')\n",
    "        plt.legend()\n",
    "        plt.savefig(f'results/no_dropout/train_loss/{model.name}_loss_{g[0]}.png')\n",
    "        plt.close()\n",
    "\n",
    "        for m in g[1].to_list():\n",
    "            m_stock_index, _, _, _ = model._get_item(m)\n",
    "            stock_index = pd.concat([stock_index, pd.Series(m_stock_index)]).drop_duplicates().astype(int)\n",
    "            inference_R = model.inference(m) # return (N, 1)\n",
    "            predict_R = model.predict(m) # reutrn (N, 1)\n",
    "\n",
    "            # move inference_R and predict_R to cpu\n",
    "            inference_R = inference_R.cpu().detach().numpy()\n",
    "            predict_R = predict_R.cpu().detach().numpy()\n",
    "\n",
    "            inference_R = pd.DataFrame(inference_R, index=m_stock_index, columns=[m])\n",
    "            predict_R = pd.DataFrame(predict_R, index=m_stock_index, columns=[m])\n",
    "\n",
    "            inference_result = pd.concat([inference_result.reset_index(drop=True), inference_R.reset_index(drop=True)], axis=1) # (N, T)\n",
    "            predict_result = pd.concat([predict_result.reset_index(drop=True), predict_R.reset_index(drop=True)], axis=1) # (N, T)\n",
    "\n",
    "            # DEBUG:\n",
    "            # save inference_R and predict_R to csv\n",
    "            # inference_result.to_csv(f'temp/{model.name}_inference_stock_{m}.csv')\n",
    "            # predict_result.to_csv(f'temp/{model.name}_predict_stock_{m}.csv')\n",
    "            \n",
    "        # refit: change train period and valid period\n",
    "        model.refit()\n",
    "\n",
    "    inference_result = pd.DataFrame(inference_result.values.T, index=test_mons, columns=CHARAS_LIST)\n",
    "    inference_result.to_csv(f'results/no_dropout/inference/{model.name}_inference.csv')\n",
    "    \n",
    "    predict_result = pd.DataFrame(predict_result.values.T, index=test_mons, columns=CHARAS_LIST)\n",
    "    predict_result.to_csv(f'results/no_dropout/predict/{model.name}_predict.csv')\n",
    "\n",
    "    # GC: release RAM memory(model)\n",
    "    del model\n",
    "    gc.collect()\n",
    "    return inference_result, predict_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_selection(model_type, model_K, omit_char=[]):\n",
    "    assert model_type in ['FF', 'PCA', 'IPCA', 'CA0', 'CA1', 'CA2', 'CA3'], f'No Such Model: {model_type}'\n",
    "    \n",
    "    if model_type == 'FF':\n",
    "        return {\n",
    "            'name': f'FF_{model_K}',\n",
    "            'omit_char': '',\n",
    "            'model': FF(K=model_K)\n",
    "        } \n",
    "            \n",
    "    elif model_type == 'PCA':\n",
    "        return {\n",
    "            'name': f'PCA_{model_K}',\n",
    "            'omit_char': omit_char,\n",
    "            'model': PCA(K=model_K, omit_char=omit_char)\n",
    "        } \n",
    "        \n",
    "    elif model_type == 'IPCA':\n",
    "        return {\n",
    "            'name': f'IPCA_{model_K}',\n",
    "            'omit_char': omit_char,\n",
    "            'model': IPCA(K=model_K, omit_char=omit_char)\n",
    "        } \n",
    "        \n",
    "    elif model_type == 'CA0':\n",
    "        return {\n",
    "            'name': f'CA0_{model_K}',\n",
    "            'omit_char': omit_char,\n",
    "            'model': CA0(hidden_size=model_K, lr=CA_LR, omit_char=omit_char)\n",
    "        } \n",
    "            \n",
    "    elif model_type == 'CA1':\n",
    "        return {\n",
    "            'name': f'CA1_{model_K}',\n",
    "            'omit_char': omit_char,\n",
    "            'model': CA1(hidden_size=model_K, dropout=CA_DR, lr=CA_LR, omit_char=omit_char)\n",
    "        } \n",
    "    \n",
    "    elif model_type == 'CA2':\n",
    "        return {\n",
    "            'name': f'CA2_{model_K}',\n",
    "            'omit_char': omit_char,\n",
    "            'model': CA2(hidden_size=model_K, dropout=CA_DR, lr=CA_LR, omit_char=omit_char)\n",
    "        } \n",
    "        \n",
    "    else:\n",
    "        return {\n",
    "            'name': f'CA3_{model_K}',\n",
    "            'omit_char': omit_char,\n",
    "            'model': CA3(hidden_size=model_K, dropout=CA_DR, lr=CA_LR, omit_char=omit_char)\n",
    "        } "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_model = model_selection('CA0', 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for g in product(['FF', 'PCA', 'IPCA', 'CA0', 'CA1', 'CA2', 'CA3'], [5]):\n",
    "    print(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--Model', type=list, default=)\n",
    "    parser.add_argument('--K', type=list, default=)\n",
    "    parser.add_argument('--omit_char', type=list, default=[])\n",
    "\n",
    "    args = parser.parse_args()\n",
    "    \n",
    "    model_set = [model_selection(g[0], g[1], args.omit_char) for g in product(args.Model, args.K)]\n",
    "        \n",
    "    models_name = []\n",
    "    R_square = []\n",
    "    for model in model_set:\n",
    "        models_name.append(model['name'])\n",
    "\n",
    "        if model['name'].split('_')[0][:-1] == 'CA':\n",
    "            model_inference_and_predict_CA(model['model'])    \n",
    "        else:\n",
    "            model_inference_and_predict(model['model'])\n",
    "        \n",
    "        gc.collect()    \n",
    "        \n",
    "        R_square.append(calculate_R2(model['model'], model['name'].split('_')[0][:-1]))\n",
    "        if len(model['omit_char']):\n",
    "            alpha_plot(model['model'], model['name'].split('_')[0][:-1], save_dir='alpha_imgs')\n",
    "\n",
    "\n",
    "    filename = f\"R_squares/{time.ctime().split(' ')[-1] + '-' + time.ctime().split(' ')[1] + '-'+ time.ctime().split(' ')[3] + ' ' + time.ctime().split(' ')[4] }.json\"\n",
    "    obj = {\n",
    "        \"models\": [],\n",
    "        'omit_char': [],\n",
    "        \"R2\": R_square,\n",
    "    }\n",
    "\n",
    "    with open(filename, \"w\") as out_file:\n",
    "        json.dump(obj, out_file)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_set = [model_selection('PCA', i+1) for i in range(6)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_1 = PCA(K=1, portfolio=True)\n",
    "pca_2 = PCA(K=2, portfolio=True)\n",
    "pca_3 = PCA(K=3, portfolio=True)\n",
    "pca_4 = PCA(K=4, portfolio=True)\n",
    "pca_5 = PCA(K=5, portfolio=True)\n",
    "pca_6 = PCA(K=6, portfolio=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_inference_and_predict(pca_1)\n",
    "# model_inference_and_predict(pca_2)\n",
    "# model_inference_and_predict(pca_3)\n",
    "# model_inference_and_predict(pca_4)\n",
    "# model_inference_and_predict(pca_5)\n",
    "# model_inference_and_predict(pca_6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ff_1 = FF(K=1, portfolio=True)\n",
    "ff_2 = FF(K=2, portfolio=True)\n",
    "ff_3 = FF(K=3, portfolio=True)\n",
    "ff_4 = FF(K=4, portfolio=True)\n",
    "ff_5 = FF(K=5, portfolio=True)\n",
    "ff_6 = FF(K=6, portfolio=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_inference_and_predict(ff_1)\n",
    "model_inference_and_predict(ff_2)\n",
    "model_inference_and_predict(ff_3)\n",
    "model_inference_and_predict(ff_4)\n",
    "model_inference_and_predict(ff_5)\n",
    "model_inference_and_predict(ff_6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_inference_and_predict_CA(model):\n",
    "    mon_list = pd.read_pickle('data/mon_list.pkl')\n",
    "    test_mons = mon_list.loc[mon_list >= model.test_period[0]]\n",
    "    inference_result = pd.DataFrame()\n",
    "    predict_result = pd.DataFrame()\n",
    "    T_bar = tqdm(test_mons.groupby(test_mons.apply(lambda x: x//10000)), colour='red', desc=f'{model.name} Inferencing & Predicting')\n",
    "    \n",
    "    stock_index = pd.Series(dtype=np.int64)\n",
    "    for g in T_bar: # rolling train\n",
    "        T_bar.set_postfix({'Year': g[0]})\n",
    "        model.train_model()\n",
    "        \n",
    "        for m in g[1].to_list():\n",
    "            m_stock_index, _, _, _ = model._get_item(m)\n",
    "            stock_index = pd.concat([stock_index, pd.Series(m_stock_index)]).drop_duplicates().astype(int)\n",
    "            inference_R = model.inference(m) # return (N, 1)\n",
    "            predict_R = model.inference(m) # reutrn (N, 1)\n",
    "\n",
    "            # move inference_R and predict_R to cpu\n",
    "            inference_R = inference_R.cpu().detach().numpy()\n",
    "            predict_R = predict_R.cpu().detach().numpy()\n",
    "\n",
    "            inference_R = pd.DataFrame(inference_R, index=m_stock_index, columns=[m])\n",
    "            predict_R = pd.DataFrame(predict_R, index=m_stock_index, columns=[m])\n",
    "\n",
    "            \n",
    "            inference_result = pd.concat([inference_result.reset_index(drop=True), inference_R.reset_index(drop=True)], axis=1) # (N, T)\n",
    "            predict_result = pd.concat([predict_result.reset_index(drop=True), predict_R.reset_index(drop=True)], axis=1) # (N, T)\n",
    "\n",
    "            # DEBUG:\n",
    "            # save inference_R and predict_R to csv\n",
    "            # inference_result.to_csv(f'temp/{model.name}_inference_stock_{m}.csv')\n",
    "            # predict_result.to_csv(f'temp/{model.name}_predict_stock_{m}.csv')\n",
    "            \n",
    "        # model refit (change train period and valid period)\n",
    "        model.refit()\n",
    "\n",
    "    inference_result = pd.DataFrame(inference_result.values, index=charas, columns=test_mons)\n",
    "    inference_result.to_csv(f'results/inference/{model.name}_inference.csv')\n",
    "    \n",
    "    predict_result = pd.DataFrame(predict_result.values, index=charas, columns=test_mons)\n",
    "    predict_result.to_csv(f'results/predict/{model.name}_predict.csv')\n",
    "    return inference_result, predict_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ca3_lists = []\n",
    "infer_results = None\n",
    "predict_results = None\n",
    "for i in range(6):\n",
    "    gc.collect()\n",
    "    ca3_lists.append(CA3(i + 1).to('cuda'))\n",
    "    print(f'begin of {ca3_lists[i].name}')\n",
    "    inference_result, predict_results = model_inference_and_predict_CA(ca3_lists[i])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myconda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
