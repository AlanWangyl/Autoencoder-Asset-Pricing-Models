{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.PCA import PCA\n",
    "from models.FF import FF\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from utils import charas\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_inference_and_predict(model):\n",
    "    mon_list = pd.read_pickle('data/mon_list.pkl')\n",
    "    test_mons = mon_list.loc[mon_list >= model.test_period[0]]\n",
    "    inference_result = []\n",
    "    predict_result = []\n",
    "    T_bar = tqdm(test_mons.groupby(test_mons.apply(lambda x: x//10000)), colour='red', desc=f'{model.name} Inferencing & Predicting')\n",
    "    \n",
    "    for g in T_bar: # rolling train\n",
    "        T_bar.set_postfix({'Year': g[0]})\n",
    "        model.train_model()\n",
    "        \n",
    "        for m in g[1].to_list():\n",
    "            inference_result.append(model.inference(m))\n",
    "            predict_result.append(model.predict(m))\n",
    "        # model refit (change train period and valid period)\n",
    "        model.refit()\n",
    "\n",
    "    inference_result = pd.DataFrame(inference_result, index=test_mons, columns=charas)\n",
    "    inference_result.to_csv(f'results/inference/{model.name}_inference.csv')\n",
    "    \n",
    "    predict_result = pd.DataFrame(predict_result, index=test_mons, columns=charas)\n",
    "    predict_result.to_csv(f'results/predict/{model.name}_predict.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_1 = PCA(K=1, portfolio=True)\n",
    "pca_2 = PCA(K=2, portfolio=True)\n",
    "pca_3 = PCA(K=3, portfolio=True)\n",
    "pca_4 = PCA(K=4, portfolio=True)\n",
    "pca_5 = PCA(K=5, portfolio=True)\n",
    "pca_6 = PCA(K=6, portfolio=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_inference_and_predict(pca_1)\n",
    "# model_inference_and_predict(pca_2)\n",
    "# model_inference_and_predict(pca_3)\n",
    "# model_inference_and_predict(pca_4)\n",
    "# model_inference_and_predict(pca_5)\n",
    "# model_inference_and_predict(pca_6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ff_1 = FF(K=1, portfolio=True)\n",
    "ff_2 = FF(K=2, portfolio=True)\n",
    "ff_3 = FF(K=3, portfolio=True)\n",
    "ff_4 = FF(K=4, portfolio=True)\n",
    "ff_5 = FF(K=5, portfolio=True)\n",
    "ff_6 = FF(K=6, portfolio=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "FF_1 Inferencing & Predicting: 100%|\u001b[31m██████████\u001b[0m| 30/30 [00:05<00:00,  5.11it/s, Year=2016]\n",
      "FF_2 Inferencing & Predicting: 100%|\u001b[31m██████████\u001b[0m| 30/30 [00:05<00:00,  5.04it/s, Year=2016]\n",
      "FF_3 Inferencing & Predicting: 100%|\u001b[31m██████████\u001b[0m| 30/30 [00:06<00:00,  4.95it/s, Year=2016]\n",
      "FF_4 Inferencing & Predicting: 100%|\u001b[31m██████████\u001b[0m| 30/30 [00:06<00:00,  4.85it/s, Year=2016]\n",
      "FF_5 Inferencing & Predicting: 100%|\u001b[31m██████████\u001b[0m| 30/30 [00:06<00:00,  4.81it/s, Year=2016]\n",
      "FF_6 Inferencing & Predicting: 100%|\u001b[31m██████████\u001b[0m| 30/30 [00:06<00:00,  4.75it/s, Year=2016]\n"
     ]
    }
   ],
   "source": [
    "model_inference_and_predict(ff_1)\n",
    "model_inference_and_predict(ff_2)\n",
    "model_inference_and_predict(ff_3)\n",
    "model_inference_and_predict(ff_4)\n",
    "model_inference_and_predict(ff_5)\n",
    "model_inference_and_predict(ff_6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_inference_and_predict_CA(model):\n",
    "    mon_list = pd.read_pickle('data/mon_list.pkl')\n",
    "    test_mons = mon_list.loc[mon_list >= model.test_period[0]]\n",
    "    inference_result = pd.DataFrame()\n",
    "    predict_result = pd.DataFrame()\n",
    "    T_bar = tqdm(test_mons.groupby(test_mons.apply(lambda x: x//10000)), colour='red', desc=f'{model.name} Inferencing & Predicting')\n",
    "    \n",
    "    stock_index = pd.Series(dtype=np.int64)\n",
    "    for g in T_bar: # rolling train\n",
    "        T_bar.set_postfix({'Year': g[0]})\n",
    "        model.train_model()\n",
    "        \n",
    "        for m in g[1].to_list():\n",
    "            m_stock_index, _, _, _ = model._get_item(m)\n",
    "            print(m_stock_index)\n",
    "            stock_index = pd.concat([stock_index, pd.Series(m_stock_index)]).drop_duplicates().astype(int)\n",
    "            inference_R = model.inference(m) # return (N, 1)\n",
    "            predict_R = model.inference(m) # reutrn (N, 1)\n",
    "\n",
    "            # move inference_R and predict_R to cpu\n",
    "            inference_R = inference_R.cpu().detach().numpy()\n",
    "            predict_R = predict_R.cpu().detach().numpy()\n",
    "\n",
    "            inference_R = pd.DataFrame(inference_R, index=m_stock_index, columns=[m]).reindex(stock_index)\n",
    "            predict_R = pd.DataFrame(predict_R, index=m_stock_index, columns=[m]).reindex(stock_index)\n",
    "\n",
    "            \n",
    "            inference_result = pd.concat([inference_result, inference_R], axis=1) # (N, T)\n",
    "            predict_result = pd.concat([predict_result, predict_R], axis=1) # (N, T)\n",
    "        # model refit (change train period and valid period)\n",
    "        model.refit()\n",
    "\n",
    "    inference_result = pd.DataFrame(inference_result, index=test_mons, columns=charas)\n",
    "    inference_result.to_csv(f'results/inference/{model.name}_inference_stock.csv')\n",
    "    \n",
    "    predict_result = pd.DataFrame(predict_result, index=test_mons, columns=charas)\n",
    "    predict_result.to_csv(f'results/predict/{model.name}_predict_stock.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.CA import CA0, CA1, CA2, CA3\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "begin of CA3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CA3 Inferencing & Predicting:   0%|\u001b[31m          \u001b[0m| 0/30 [00:00<?, ?it/s, Year=1987]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index([10000.0, 10001.0, 10002.0, 10003.0, 10005.0, 10007.0, 10008.0, 10009.0,\n",
      "       10010.0, 10012.0,\n",
      "       ...\n",
      "       93121.0, 93156.0, 93164.0, 93201.0, 93220.0, 93236.0, 93252.0, 93279.0,\n",
      "       93287.0, 93316.0],\n",
      "      dtype='float64', name='permno', length=6600)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CA3 Inferencing & Predicting:   0%|\u001b[31m          \u001b[0m| 0/30 [00:30<?, ?it/s, Year=1987]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m ca3_lists\u001b[39m.\u001b[39mappend(CA3(i \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m)\u001b[39m.\u001b[39mto(\u001b[39m'\u001b[39m\u001b[39mcuda\u001b[39m\u001b[39m'\u001b[39m))\n\u001b[0;32m      5\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mbegin of \u001b[39m\u001b[39m{\u001b[39;00mca3_lists[i]\u001b[39m.\u001b[39mname\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[1;32m----> 6\u001b[0m model_inference_and_predict_CA(ca3_lists[i])\n",
      "Cell \u001b[1;32mIn[19], line 19\u001b[0m, in \u001b[0;36mmodel_inference_and_predict_CA\u001b[1;34m(model)\u001b[0m\n\u001b[0;32m     17\u001b[0m inference_R \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39minference(m) \u001b[39m# return (N, 1)\u001b[39;00m\n\u001b[0;32m     18\u001b[0m predict_R \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39minference(m) \u001b[39m# reutrn (N, 1)\u001b[39;00m\n\u001b[1;32m---> 19\u001b[0m inference_R \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mDataFrame(inference_R, index\u001b[39m=\u001b[39;49mm_stock_index, columns\u001b[39m=\u001b[39;49m[m])\u001b[39m.\u001b[39mreindex(stock_index)\n\u001b[0;32m     20\u001b[0m predict_R \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame(predict_R, index\u001b[39m=\u001b[39mm_stock_index, columns\u001b[39m=\u001b[39m[m])\u001b[39m.\u001b[39mreindex(stock_index)\n\u001b[0;32m     22\u001b[0m inference_result \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mconcat([inference_result, inference_R], axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m) \u001b[39m# (N, T)\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\pandas\\core\\frame.py:771\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    768\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(data, abc\u001b[39m.\u001b[39mSequence):\n\u001b[0;32m    769\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(data, \u001b[39m\"\u001b[39m\u001b[39m__array__\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m    770\u001b[0m         \u001b[39m# GH#44616 big perf improvement for e.g. pytorch tensor\u001b[39;00m\n\u001b[1;32m--> 771\u001b[0m         data \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49masarray(data)\n\u001b[0;32m    772\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    773\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(data)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\_tensor.py:970\u001b[0m, in \u001b[0;36mTensor.__array__\u001b[1;34m(self, dtype)\u001b[0m\n\u001b[0;32m    968\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(Tensor\u001b[39m.\u001b[39m__array__, (\u001b[39mself\u001b[39m,), \u001b[39mself\u001b[39m, dtype\u001b[39m=\u001b[39mdtype)\n\u001b[0;32m    969\u001b[0m \u001b[39mif\u001b[39;00m dtype \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 970\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnumpy()\n\u001b[0;32m    971\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    972\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnumpy()\u001b[39m.\u001b[39mastype(dtype, copy\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "\u001b[1;31mTypeError\u001b[0m: can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first."
     ]
    }
   ],
   "source": [
    "ca3_lists = []\n",
    "for i in range(6):\n",
    "    gc.collect()\n",
    "    ca3_lists.append(CA3(i + 1).to('cuda'))\n",
    "    print(f'begin of {ca3_lists[i].name}')\n",
    "    model_inference_and_predict_CA(ca3_lists[i])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myconda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
