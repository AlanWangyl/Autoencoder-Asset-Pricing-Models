{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from models.PCA import PCA\n",
    "from models.FF import FF\n",
    "from models.IPCA import IPCA\n",
    "from models.CA import CA0, CA1, CA2, CA3\n",
    "\n",
    "import gc\n",
    "import argparse\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "from utils import *\n",
    "from analysis import *\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import product\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_inference_and_predict(model):\n",
    "    \"\"\"\n",
    "    Inference and Prediction of non NN models:\n",
    "    Returns: model.name_inference.csv & model.name_inference.csv saved in path 'results'\n",
    "    \"\"\"\n",
    "    mon_list = pd.read_pickle('data/mon_list.pkl')\n",
    "    test_mons = mon_list.loc[mon_list >= model.test_period[0]]\n",
    "    inference_result = []\n",
    "    predict_result = []\n",
    "    T_bar = tqdm(test_mons.groupby(test_mons.apply(lambda x: x//10000)), colour='red', desc=f'{model.name} Inferencing & Predicting')\n",
    "    \n",
    "    for g in T_bar: # rolling train\n",
    "        T_bar.set_postfix({'Year': g[0]})\n",
    "        model.train_model()\n",
    "        \n",
    "        for m in g[1].to_list():\n",
    "            inference_result.append(model.inference(m))\n",
    "            predict_result.append(model.predict(m))\n",
    "        # model refit (change train period and valid period)\n",
    "        model.refit()\n",
    "\n",
    "    inference_result = pd.DataFrame(inference_result, index=test_mons, columns=CHARAS_LIST)\n",
    "    inference_result.to_csv(f'results/inference/{model.name}_inference.csv')\n",
    "    \n",
    "    predict_result = pd.DataFrame(predict_result, index=test_mons, columns=CHARAS_LIST)\n",
    "    predict_result.to_csv(f'results/predict/{model.name}_predict.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_inference_and_predict_CA(model):\n",
    "    \"\"\"\n",
    "    Inference and Prediction of NN models:\n",
    "    Returns: model.name_inference.csv & model.name_inference.csv saved in path 'results'\n",
    "    \"\"\"\n",
    "    mon_list = pd.read_pickle('data/mon_list.pkl')\n",
    "    test_mons = mon_list.loc[mon_list >= model.test_period[0]]\n",
    "    inference_result = pd.DataFrame()\n",
    "    predict_result = pd.DataFrame()\n",
    "    T_bar = tqdm(test_mons.groupby(test_mons.apply(lambda x: x//10000)), colour='red', desc=f'{model.name} Inferencing & Predicting')\n",
    "    \n",
    "    stock_index = pd.Series(dtype=np.int64)\n",
    "    for g in T_bar: # rolling train\n",
    "        T_bar.set_postfix({'Year': g[0]})\n",
    "\n",
    "        model.reset_weight()\n",
    "        model.release_gpu()\n",
    "        # release GPU memory\n",
    "        for _ in range(6): # call function multiple times to clear the cuda cache\n",
    "            torch.cuda.empty_cache()\n",
    "            \n",
    "        train_loss, val_loss = model.train_model()\n",
    "        # plot loss\n",
    "        plt.plot(train_loss, label='train_loss')\n",
    "        plt.plot(val_loss, label='val_loss')\n",
    "        plt.legend()\n",
    "        plt.savefig(f'results/no_dropout/train_loss/{model.name}_loss_{g[0]}.png')\n",
    "        plt.close()\n",
    "\n",
    "        for m in g[1].to_list():\n",
    "            m_stock_index, _, _, _ = model._get_item(m)\n",
    "            stock_index = pd.concat([stock_index, pd.Series(m_stock_index)]).drop_duplicates().astype(int)\n",
    "            inference_R = model.inference(m) # return (N, 1)\n",
    "            predict_R = model.predict(m) # reutrn (N, 1)\n",
    "\n",
    "            # move inference_R and predict_R to cpu\n",
    "            inference_R = inference_R.cpu().detach().numpy()\n",
    "            predict_R = predict_R.cpu().detach().numpy()\n",
    "\n",
    "            inference_R = pd.DataFrame(inference_R, index=m_stock_index, columns=[m])\n",
    "            predict_R = pd.DataFrame(predict_R, index=m_stock_index, columns=[m])\n",
    "\n",
    "            inference_result = pd.concat([inference_result.reset_index(drop=True), inference_R.reset_index(drop=True)], axis=1) # (N, T)\n",
    "            predict_result = pd.concat([predict_result.reset_index(drop=True), predict_R.reset_index(drop=True)], axis=1) # (N, T)\n",
    "\n",
    "            # DEBUG:\n",
    "            # save inference_R and predict_R to csv\n",
    "            # inference_result.to_csv(f'temp/{model.name}_inference_stock_{m}.csv')\n",
    "            # predict_result.to_csv(f'temp/{model.name}_predict_stock_{m}.csv')\n",
    "            \n",
    "        # refit: change train period and valid period\n",
    "        model.refit()\n",
    "\n",
    "    inference_result = pd.DataFrame(inference_result.values.T, index=test_mons, columns=CHARAS_LIST)\n",
    "    inference_result.to_csv(f'results/no_dropout/inference/{model.name}_inference.csv')\n",
    "    \n",
    "    predict_result = pd.DataFrame(predict_result.values.T, index=test_mons, columns=CHARAS_LIST)\n",
    "    predict_result.to_csv(f'results/no_dropout/predict/{model.name}_predict.csv')\n",
    "\n",
    "    # GC: release RAM memory(model)\n",
    "    del model\n",
    "    gc.collect()\n",
    "    return inference_result, predict_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_selection(model_type, model_K, omit_char=[]):\n",
    "    assert model_type in ['FF', 'PCA', 'IPCA', 'CA0', 'CA1', 'CA2', 'CA3'], f'No Such Model: {model_type}'\n",
    "    \n",
    "    if model_type == 'FF':\n",
    "        return {\n",
    "            'name': f'FF_{model_K}',\n",
    "            'omit_char': '',\n",
    "            'model': FF(K=model_K)\n",
    "        } \n",
    "            \n",
    "    elif model_type == 'PCA':\n",
    "        return {\n",
    "            'name': f'PCA_{model_K}',\n",
    "            'omit_char': omit_char,\n",
    "            'model': PCA(K=model_K, omit_char=omit_char)\n",
    "        } \n",
    "        \n",
    "    elif model_type == 'IPCA':\n",
    "        return {\n",
    "            'name': f'IPCA_{model_K}',\n",
    "            'omit_char': omit_char,\n",
    "            'model': IPCA(K=model_K, omit_char=omit_char)\n",
    "        } \n",
    "        \n",
    "    elif model_type == 'CA0':\n",
    "        return {\n",
    "            'name': f'CA0_{model_K}',\n",
    "            'omit_char': omit_char,\n",
    "            'model': CA0(hidden_size=model_K, lr=CA_LR, omit_char=omit_char)\n",
    "        } \n",
    "            \n",
    "    elif model_type == 'CA1':\n",
    "        return {\n",
    "            'name': f'CA1_{model_K}',\n",
    "            'omit_char': omit_char,\n",
    "            'model': CA1(hidden_size=model_K, dropout=CA_DR, lr=CA_LR, omit_char=omit_char)\n",
    "        } \n",
    "    \n",
    "    elif model_type == 'CA2':\n",
    "        return {\n",
    "            'name': f'CA2_{model_K}',\n",
    "            'omit_char': omit_char,\n",
    "            'model': CA2(hidden_size=model_K, dropout=CA_DR, lr=CA_LR, omit_char=omit_char)\n",
    "        } \n",
    "        \n",
    "    else:\n",
    "        return {\n",
    "            'name': f'CA3_{model_K}',\n",
    "            'omit_char': omit_char,\n",
    "            'model': CA3(hidden_size=model_K, dropout=CA_DR, lr=CA_LR, omit_char=omit_char)\n",
    "        } "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for g in product(['FF', 'PCA', 'IPCA', 'CA0', 'CA1', 'CA2', 'CA3'], [5]):\n",
    "    print(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--Model', type=list, default=)\n",
    "    parser.add_argument('--K', type=list, default=)\n",
    "    parser.add_argument('--omit_char', type=list, default=[])\n",
    "\n",
    "    args = parser.parse_args()\n",
    "    \n",
    "    model_set = [model_selection(g[0], g[1], args.omit_char) for g in product(args.Model, args.K)]\n",
    "        \n",
    "    models_name = []\n",
    "    R_square = []\n",
    "    for model in model_set:\n",
    "        models_name.append(model['name'])\n",
    "\n",
    "        if model['name'].split('_')[0][:-1] == 'CA':\n",
    "            model_inference_and_predict_CA(model['model'])    \n",
    "        else:\n",
    "            model_inference_and_predict(model['model'])\n",
    "        \n",
    "        gc.collect()    \n",
    "        \n",
    "        R_square.append(calculate_R2(model['model'], model['name'].split('_')[0][:-1]))\n",
    "        if len(model['omit_char']):\n",
    "            alpha_plot(model['model'], model['name'].split('_')[0][:-1], save_dir='alpha_imgs')\n",
    "\n",
    "\n",
    "    filename = f\"R_squares/{time.ctime().split(' ')[-1] + '-' + time.ctime().split(' ')[1] + '-'+ time.ctime().split(' ')[3] + ' ' + time.ctime().split(' ')[4] }.json\"\n",
    "    obj = {\n",
    "        \"models\": [],\n",
    "        'omit_char': [],\n",
    "        \"R2\": R_square,\n",
    "    }\n",
    "\n",
    "    with open(filename, \"w\") as out_file:\n",
    "        json.dump(obj, out_file)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# basic analysis with all characteristics => calculate R^2 and save analysis plot\n",
    "\n",
    "\n",
    "\n",
    "# analysis certain characteristic's importance => calculate R^2 delta\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Get these from input\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_set = [model_selection('PCA', i+1) for i in range(6)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_1 = PCA(K=1, portfolio=True)\n",
    "pca_2 = PCA(K=2, portfolio=True)\n",
    "pca_3 = PCA(K=3, portfolio=True)\n",
    "pca_4 = PCA(K=4, portfolio=True)\n",
    "pca_5 = PCA(K=5, portfolio=True)\n",
    "pca_6 = PCA(K=6, portfolio=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_inference_and_predict(pca_1)\n",
    "# model_inference_and_predict(pca_2)\n",
    "# model_inference_and_predict(pca_3)\n",
    "# model_inference_and_predict(pca_4)\n",
    "# model_inference_and_predict(pca_5)\n",
    "# model_inference_and_predict(pca_6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ff_1 = FF(K=1, portfolio=True)\n",
    "ff_2 = FF(K=2, portfolio=True)\n",
    "ff_3 = FF(K=3, portfolio=True)\n",
    "ff_4 = FF(K=4, portfolio=True)\n",
    "ff_5 = FF(K=5, portfolio=True)\n",
    "ff_6 = FF(K=6, portfolio=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_inference_and_predict(ff_1)\n",
    "model_inference_and_predict(ff_2)\n",
    "model_inference_and_predict(ff_3)\n",
    "model_inference_and_predict(ff_4)\n",
    "model_inference_and_predict(ff_5)\n",
    "model_inference_and_predict(ff_6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_inference_and_predict_CA(model):\n",
    "    mon_list = pd.read_pickle('data/mon_list.pkl')\n",
    "    test_mons = mon_list.loc[mon_list >= model.test_period[0]]\n",
    "    inference_result = pd.DataFrame()\n",
    "    predict_result = pd.DataFrame()\n",
    "    T_bar = tqdm(test_mons.groupby(test_mons.apply(lambda x: x//10000)), colour='red', desc=f'{model.name} Inferencing & Predicting')\n",
    "    \n",
    "    stock_index = pd.Series(dtype=np.int64)\n",
    "    for g in T_bar: # rolling train\n",
    "        T_bar.set_postfix({'Year': g[0]})\n",
    "        model.train_model()\n",
    "        \n",
    "        for m in g[1].to_list():\n",
    "            m_stock_index, _, _, _ = model._get_item(m)\n",
    "            stock_index = pd.concat([stock_index, pd.Series(m_stock_index)]).drop_duplicates().astype(int)\n",
    "            inference_R = model.inference(m) # return (N, 1)\n",
    "            predict_R = model.inference(m) # reutrn (N, 1)\n",
    "\n",
    "            # move inference_R and predict_R to cpu\n",
    "            inference_R = inference_R.cpu().detach().numpy()\n",
    "            predict_R = predict_R.cpu().detach().numpy()\n",
    "\n",
    "            inference_R = pd.DataFrame(inference_R, index=m_stock_index, columns=[m])\n",
    "            predict_R = pd.DataFrame(predict_R, index=m_stock_index, columns=[m])\n",
    "\n",
    "            \n",
    "            inference_result = pd.concat([inference_result.reset_index(drop=True), inference_R.reset_index(drop=True)], axis=1) # (N, T)\n",
    "            predict_result = pd.concat([predict_result.reset_index(drop=True), predict_R.reset_index(drop=True)], axis=1) # (N, T)\n",
    "\n",
    "            # DEBUG:\n",
    "            # save inference_R and predict_R to csv\n",
    "            # inference_result.to_csv(f'temp/{model.name}_inference_stock_{m}.csv')\n",
    "            # predict_result.to_csv(f'temp/{model.name}_predict_stock_{m}.csv')\n",
    "            \n",
    "        # model refit (change train period and valid period)\n",
    "        model.refit()\n",
    "\n",
    "    inference_result = pd.DataFrame(inference_result.values, index=charas, columns=test_mons)\n",
    "    inference_result.to_csv(f'results/inference/{model.name}_inference.csv')\n",
    "    \n",
    "    predict_result = pd.DataFrame(predict_result.values, index=charas, columns=test_mons)\n",
    "    predict_result.to_csv(f'results/predict/{model.name}_predict.csv')\n",
    "    return inference_result, predict_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ca3_lists = []\n",
    "infer_results = None\n",
    "predict_results = None\n",
    "for i in range(6):\n",
    "    gc.collect()\n",
    "    ca3_lists.append(CA3(i + 1).to('cuda'))\n",
    "    print(f'begin of {ca3_lists[i].name}')\n",
    "    inference_result, predict_results = model_inference_and_predict_CA(ca3_lists[i])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myconda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
