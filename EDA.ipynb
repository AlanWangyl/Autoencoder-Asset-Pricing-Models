{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from utils import CHARAS_LIST\n",
    "import zipfile\n",
    "from tqdm import tqdm\n",
    "from joblib import delayed, Parallel\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.PCA import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading datashare.pkl Done!\n"
     ]
    }
   ],
   "source": [
    "with zipfile.ZipFile('data.zip', 'r') as z:  \n",
    "    with z.open('data/datashare.pkl') as f:\n",
    "        print('Reading datashare.pkl', end=' ')\n",
    "        datashare = pd.read_pickle(f)\n",
    "        datashare['DATE'].drop_duplicates().reset_index(drop=True).to_pickle('data/mon_list.pkl')\n",
    "        # datashare.to_pickle('data/datashare.pkl')\n",
    "        print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_process(date):\n",
    "    cross_slice = datashare.loc[datashare.DATE == date].copy(deep=False)\n",
    "    omitted_mask = 1.0 * np.isnan(cross_slice.loc[cross_slice['DATE'] == date])\n",
    "    # fill nan values with each factors median\n",
    "    cross_slice.loc[cross_slice.DATE == date] = cross_slice.fillna(0) + omitted_mask * cross_slice.median()\n",
    "    # if all stocks' factor is nan, fill by zero\n",
    "    cross_slice.loc[cross_slice.DATE == date] = cross_slice.fillna(0)\n",
    "\n",
    "    re_df = []\n",
    "    # rank normalization\n",
    "    for col in CHARAS_LIST:\n",
    "        series = cross_slice[col]\n",
    "        de_duplicate_slice = pd.DataFrame(series.drop_duplicates().to_list(), columns=['chara'])\n",
    "        series = pd.DataFrame(series.to_list(), columns=['chara'])\n",
    "        \n",
    "        de_duplicate_slice['sort_rank'] = de_duplicate_slice['chara'].argsort().argsort()\n",
    "        rank = pd.merge(series, de_duplicate_slice, left_on='chara', right_on='chara', how='right')['sort_rank']\n",
    "        # if all values are zero, the results will contain nan\n",
    "        rank_normal = ((rank - rank.min())/(rank.max() - rank.min())*2 - 1)\n",
    "        re_df.append(rank_normal)\n",
    "    re_df = pd.DataFrame(re_df, index=CHARAS_LIST).T.fillna(0)\n",
    "    re_df['permno'] = list(cross_slice['permno'].astype(int))\n",
    "    re_df['DATE'] = list(cross_slice['DATE'].astype(int))\n",
    "    \n",
    "    return re_df[['permno', 'DATE'] + CHARAS_LIST]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_df = pre_process(19570329)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: 100%|\u001b[32m██████████\u001b[0m| 718/718 [02:04<00:00,  5.76it/s]\n"
     ]
    }
   ],
   "source": [
    "processed_df = Parallel(n_jobs=-1)(delayed(pre_process)(d) for d in tqdm(datashare.DATE.drop_duplicates().to_list(), colour='green', desc='Processing'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_df = pd.concat(processed_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rank_normal_series(datashare['acc']).hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datashare_re = datashare[['permno', 'DATE']].copy(deep=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in tqdm(CHARAS_LIST):\n",
    "    datashare_re[col] = rank_normal_series(datashare[col])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datashare_chara.loc[datashare_chara.DATE == 19670331]['acc'].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datashare_chara['acc'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myconda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
